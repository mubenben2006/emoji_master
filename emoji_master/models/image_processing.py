import numpy as np
from PIL import Image, ImageEnhance
from config import Config


class FaceProcessor:
    """å®Œæ•´çš„äººè„¸å¤„ç†æ¨¡å— - æ”¯æŒåŒç«¯åƒç´ è°ƒæ•´å’Œé€æ˜èƒŒæ™¯"""

    def __init__(self, face_detector):
        self.face_detector = face_detector
        self.enhance_params = Config.IMAGE_ENHANCE_PARAMS

    def process_face(self, face_image, processing_params=None, ellipse_info=None):
        """å¤„ç†äººè„¸å›¾åƒ - å®Œå…¨æ”¯æŒäº®æš—å‚æ•°è°ƒæ•´"""
        if processing_params is None:
            processing_params = Config.DEFAULT_PROCESS_PARAMS.copy()

        try:
            print(f"ğŸ¨ å¼€å§‹äººè„¸å¤„ç†: è¾“å…¥å°ºå¯¸{face_image.size}")
            print(f"ğŸ“Š å¤„ç†å‚æ•°: {processing_params}")

            # ç¡®ä¿RGBAæ ¼å¼ä»¥ä¿æŒé€æ˜åº¦
            if face_image.mode != 'RGBA':
                face_image = face_image.convert('RGBA')

            # åˆ†ç¦»RGBå’ŒAlphaé€šé“
            rgb_image = face_image.convert('RGB')
            alpha_channel = face_image.getchannel('A')

            # æ­¥éª¤1: åº”ç”¨æ–°çš„äº®æš—è°ƒæ•´ç®—æ³•
            adjusted_rgb = self._new_brightness_adjustment(
                rgb_image,
                brighten_factor=processing_params['brighten_factor'],
                darken_factor=processing_params['darken_factor'],
                low_cutoff_percent=processing_params['low_cutoff_percent'],
                high_cutoff_percent=processing_params['high_cutoff_percent']
            )

            # æ­¥éª¤2: åº”ç”¨å®Œæ•´å›¾åƒå¢å¼º
            enhanced_rgb = self._enhance_image(adjusted_rgb)

            # æ­¥éª¤3: è½¬æ¢ä¸ºé»‘ç™½è¡¨æƒ…åŒ…é£æ ¼
            bw_rgb = self._convert_to_emoji_style(enhanced_rgb)

            # é‡æ–°ç»„åˆRGBå’ŒAlphaé€šé“
            bw_rgba = Image.merge('RGBA', (*bw_rgb.split(), alpha_channel))

            # æ­¥éª¤4: åº”ç”¨è¾¹ç•Œæ¸…ç†
            border_pixels = processing_params.get('border_cleanup_pixels', 2)
            if ellipse_info and border_pixels > 0:
                final_face = self.face_detector.apply_border_cleanup(
                    bw_rgba, ellipse_info, border_pixels
                )
                print(f"âœ… è¾¹ç•Œæ¸…ç†å®Œæˆ: {border_pixels}åƒç´ ")
            else:
                final_face = bw_rgba
                print("âš ï¸ æœªè¿›è¡Œè¾¹ç•Œæ¸…ç†")

            print(f"âœ… äººè„¸å¤„ç†å®Œæˆ: è¾“å‡ºå°ºå¯¸{final_face.size}")
            return final_face

        except Exception as e:
            print(f"âŒ äººè„¸å¤„ç†é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return face_image

    def _new_brightness_adjustment(self, image, low_cutoff_percent=30, high_cutoff_percent=20,
                                   darken_factor=50, brighten_factor=50):
        """æ–°çš„äº®æš—è°ƒæ•´ç®—æ³•ï¼šæŒ‰å…¬å¼è°ƒæ•´åƒç´ å€¼"""
        try:
            print("ğŸ¯ åº”ç”¨æ–°çš„äº®æš—è°ƒæ•´ç®—æ³•...")
            print(f"ğŸ“Š ä½¿ç”¨å‚æ•°:")
            print(f"   - æš—æ¯”ä¾‹: {darken_factor}%")
            print(f"   - äº®æ¯”ä¾‹: {brighten_factor}%")
            print(f"   - æš—é˜ˆå€¼: {low_cutoff_percent}% (æœ€æš—çš„åƒç´ ç™¾åˆ†æ¯”)")
            print(f"   - äº®é˜ˆå€¼: {high_cutoff_percent}% (æœ€äº®çš„åƒç´ ç™¾åˆ†æ¯”)")

            # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶è½¬ä¸ºfloatç±»å‹
            img_array = np.array(image).astype(np.float32)

            # è®¡ç®—ç°åº¦å€¼
            gray = np.mean(img_array, axis=2)

            # è®¡ç®—é˜ˆå€¼ - æš—é˜ˆå€¼ï¼šæœ€æš—çš„low_cutoff_percent%åƒç´ 
            # äº®é˜ˆå€¼ï¼šæœ€äº®çš„high_cutoff_percent%åƒç´ 
            flat_gray = gray.flatten()

            # æš—é˜ˆå€¼ï¼šè®¡ç®—æœ€æš—çš„low_cutoff_percent%åƒç´ çš„é˜ˆå€¼
            dark_threshold = np.percentile(flat_gray, low_cutoff_percent)

            # äº®é˜ˆå€¼ï¼šè®¡ç®—æœ€äº®çš„high_cutoff_percent%åƒç´ çš„é˜ˆå€¼
            # æ³¨æ„ï¼špercentileçš„ç¬¬100-high_cutoff_percentç™¾åˆ†ä½è¡¨ç¤ºæœ€äº®çš„high_cutoff_percent%åƒç´ 
            bright_threshold = np.percentile(flat_gray, 100 - high_cutoff_percent)

            # åˆ›å»ºç»“æœæ•°ç»„
            result = img_array.copy()

            # å°†å‚æ•°è½¬æ¢ä¸º0-1çš„å°æ•°
            darken_factor_dec = darken_factor / 100.0
            brighten_factor_dec = brighten_factor / 100.0

            # åº”ç”¨è°ƒæ•´å…¬å¼
            for c in range(3):  # å¯¹æ¯ä¸ªRGBé€šé“
                channel = img_array[:, :, c]

                # å¯¹æš—éƒ¨åŒºåŸŸï¼šæš—å‚æ•° Ã— (åƒç´ å€¼ - 0)
                # åªå¤„ç†æœ€æš—çš„low_cutoff_percent%åƒç´ 
                dark_mask = gray <= dark_threshold
                if np.any(dark_mask):
                    dark_adjustment = channel[dark_mask] * darken_factor_dec
                    result[dark_mask, c] = np.clip(channel[dark_mask] - dark_adjustment, 0, 255)

                # å¯¹äº®éƒ¨åŒºåŸŸï¼šäº®å‚æ•° Ã— (255 - åƒç´ å€¼)
                # åªå¤„ç†æœ€äº®çš„high_cutoff_percent%åƒç´ 
                bright_mask = gray >= bright_threshold
                if np.any(bright_mask):
                    bright_adjustment = (255 - channel[bright_mask]) * brighten_factor_dec
                    result[bright_mask, c] = np.clip(channel[bright_mask] + bright_adjustment, 0, 255)

            # é™åˆ¶åœ¨0-255èŒƒå›´å†…å¹¶è½¬æ¢å›uint8
            result = np.clip(result, 0, 255).astype(np.uint8)

            # è½¬æ¢ä¸ºPILå›¾åƒ
            result_image = Image.fromarray(result)

            print(f"ğŸ“Š æ–°äº®æš—è°ƒæ•´å®Œæˆ:")
            print(f"   - æš—é˜ˆå€¼: {dark_threshold:.1f} (æœ€æš—çš„{low_cutoff_percent}%åƒç´ )")
            print(f"   - äº®é˜ˆå€¼: {bright_threshold:.1f} (æœ€äº®çš„{high_cutoff_percent}%åƒç´ )")
            print(f"   - å˜æš—åƒç´ æ•°: {np.sum(dark_mask)}")
            print(f"   - å˜äº®åƒç´ æ•°: {np.sum(bright_mask)}")

            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å åŒºåŸŸ
            overlap_mask = dark_mask & bright_mask
            if np.any(overlap_mask):
                print(f"   âš ï¸ æ³¨æ„: æœ‰{np.sum(overlap_mask)}ä¸ªåƒç´ åŒæ—¶å±äºæš—éƒ¨å’Œäº®éƒ¨åŒºåŸŸ")
                print(f"     æš—é˜ˆå€¼: {dark_threshold:.1f}, äº®é˜ˆå€¼: {bright_threshold:.1f}")

            return result_image

        except Exception as e:
            print(f"âš ï¸ äº®æš—è°ƒæ•´å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return image

    def _enhance_image(self, image):
        """å¢å¼ºå›¾åƒè´¨é‡ - ä½¿ç”¨é…ç½®ä¸­çš„æ‰€æœ‰å‚æ•°"""
        print("ğŸ¨ åº”ç”¨å›¾åƒå¢å¼º...")
        print(f"ğŸ“Š ä½¿ç”¨å‚æ•°: {self.enhance_params}")

        # äº®åº¦è°ƒæ•´
        if self.enhance_params['brightness'] != 1.0:
            enhancer = ImageEnhance.Brightness(image)
            image = enhancer.enhance(self.enhance_params['brightness'])
            print(f"   âœ… äº®åº¦è°ƒæ•´: {self.enhance_params['brightness']}")

        # æ›å…‰è°ƒæ•´
        if self.enhance_params['exposure'] != 1.0:
            enhancer = ImageEnhance.Brightness(image)
            image = enhancer.enhance(self.enhance_params['exposure'])
            print(f"   âœ… æ›å…‰è°ƒæ•´: {self.enhance_params['exposure']}")

        # å¯¹æ¯”åº¦è°ƒæ•´
        if self.enhance_params['contrast'] != 1.0:
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(self.enhance_params['contrast'])
            print(f"   âœ… å¯¹æ¯”åº¦è°ƒæ•´: {self.enhance_params['contrast']}")

        # é¥±å’Œåº¦è°ƒæ•´
        if self.enhance_params['saturation'] != 1.0:
            enhancer = ImageEnhance.Color(image)
            image = enhancer.enhance(self.enhance_params['saturation'])
            print(f"   âœ… é¥±å’Œåº¦è°ƒæ•´: {self.enhance_params['saturation']}")

        # è‡ªç„¶é¥±å’Œåº¦è°ƒæ•´
        if self.enhance_params['vibrance'] != 0:
            image = self._adjust_vibrance(image, self.enhance_params['vibrance'])
            print(f"   âœ… è‡ªç„¶é¥±å’Œåº¦è°ƒæ•´: {self.enhance_params['vibrance']}")

        # è‰²æ¸©è°ƒæ•´
        if self.enhance_params['temperature'] != 0:
            image = self._adjust_color_temperature(image, self.enhance_params['temperature'])
            print(f"   âœ… è‰²æ¸©è°ƒæ•´: {self.enhance_params['temperature']}")

        # è‰²è°ƒè°ƒæ•´
        if self.enhance_params['hue'] != 0:
            image = self._adjust_hue(image, self.enhance_params['hue'])
            print(f"   âœ… è‰²è°ƒè°ƒæ•´: {self.enhance_params['hue']}")

        # å…‰æ„Ÿè°ƒæ•´
        if self.enhance_params['lightness'] != 1.0:
            image = self._adjust_lightness(image, self.enhance_params['lightness'])
            print(f"   âœ… å…‰æ„Ÿè°ƒæ•´: {self.enhance_params['lightness']}")

        print("âœ… å›¾åƒå¢å¼ºå®Œæˆ")
        return image

    def _convert_to_emoji_style(self, image):
        """è½¬æ¢ä¸ºè¡¨æƒ…åŒ…é£æ ¼ï¼šé»‘ç™½+å¢å¼ºå¯¹æ¯”åº¦"""
        print("âš«âšª è½¬æ¢ä¸ºé»‘ç™½è¡¨æƒ…åŒ…é£æ ¼...")

        # è½¬æ¢ä¸ºç°åº¦
        bw_image = image.convert('L')

        # å¢å¼ºå¯¹æ¯”åº¦
        enhancer = ImageEnhance.Contrast(bw_image)
        bw_image = enhancer.enhance(1.2)

        # è½¬æ¢ä¸ºRGBï¼ˆä¸‰é€šé“é»‘ç™½ï¼‰
        bw_rgb = bw_image.convert('RGB')

        print("âœ… é»‘ç™½è½¬æ¢å®Œæˆ")
        return bw_rgb

    def _adjust_vibrance(self, image, vibrance_change):
        """è°ƒæ•´è‡ªç„¶é¥±å’Œåº¦"""
        if vibrance_change != 0:
            hsv_image = image.convert('HSV')
            h, s, v = hsv_image.split()

            s_array = np.array(s, dtype=np.float32) / 255.0

            enhanced_s = np.where(
                s_array < 0.5,
                s_array * (1 + vibrance_change / 100),
                s_array * (1 + vibrance_change / 200)
            )

            enhanced_s = np.clip(enhanced_s, 0, 1) * 255
            enhanced_s = Image.fromarray(enhanced_s.astype(np.uint8))

            enhanced_hsv = Image.merge('HSV', (h, enhanced_s, v))
            return enhanced_hsv.convert('RGB')
        return image

    def _adjust_color_temperature(self, image, temp_change):
        """è°ƒæ•´è‰²æ¸©"""
        if temp_change == 0:
            return image

        img_array = np.array(image)
        r, g, b = img_array[:, :, 0], img_array[:, :, 1], img_array[:, :, 2]

        r = np.clip(r.astype('float') + temp_change, 0, 255)
        g = np.clip(g.astype('float') + temp_change * 0.3, 0, 255)
        b = np.clip(b.astype('float') - temp_change * 0.5, 0, 255)

        img_array[:, :, 0] = r.astype('uint8')
        img_array[:, :, 1] = g.astype('uint8')
        img_array[:, :, 2] = b.astype('uint8')

        return Image.fromarray(img_array)

    def _adjust_hue(self, image, hue_change):
        """è°ƒæ•´è‰²è°ƒ"""
        if hue_change == 0:
            return image

        hsv_image = image.convert('HSV')
        h, s, v = hsv_image.split()

        hue_shift = int(hue_change * 255 / 100)
        h = h.point(lambda x: (x + hue_shift) % 256)

        return Image.merge('HSV', (h, s, v)).convert('RGB')

    def _adjust_lightness(self, image, lightness_change):
        """è°ƒæ•´å…‰æ„Ÿ"""
        if lightness_change == 1.0:
            return image

        enhancer = ImageEnhance.Brightness(image)
        return enhancer.enhance(lightness_change)
