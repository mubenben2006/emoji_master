import cv2
import numpy as np
from PIL import Image
import os
from config import Config


class FaceDetector:
    """äººè„¸æ£€æµ‹æ¨¡å— - åŸºäºæ¤­åœ†è£å‰ªçš„å¯é ç‰ˆæœ¬"""

    def __init__(self):
        # åŠ è½½åŸºç¡€äººè„¸æ£€æµ‹å™¨
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )

        # åŠ è½½å¯ç”¨çš„äº”å®˜æ£€æµ‹å™¨
        self.eye_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_eye.xml'
        )

        # é¼»å­å’Œå˜´å·´æ£€æµ‹å™¨åˆå§‹åŒ–ä¸ºNone
        self.nose_cascade = None
        self.mouth_cascade = None

        # æ£€æŸ¥å¹¶åˆå§‹åŒ–æ‰€æœ‰çº§è”å™¨
        self._initialize_cascades()
        print("âœ… äººè„¸æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")

    def _initialize_cascades(self):
        """åˆå§‹åŒ–çº§è”åˆ†ç±»å™¨"""
        print("ğŸ”§ åˆå§‹åŒ–é¢éƒ¨ç‰¹å¾æ£€æµ‹å™¨...")

        # å¯é€‰çš„çº§è”å™¨
        optional_cascades = {
            'nose': 'haarcascade_mcs_nose.xml',
            'mouth': 'haarcascade_smile.xml'
        }

        # æ£€æŸ¥å¯é€‰çº§è”å™¨ï¼Œå¦‚æœä¸å­˜åœ¨å°±è·³è¿‡
        for name, filename in optional_cascades.items():
            cascade_path = cv2.data.haarcascades + filename
            if os.path.exists(cascade_path):
                if name == 'nose':
                    self.nose_cascade = cv2.CascadeClassifier(cascade_path)
                elif name == 'mouth':
                    self.mouth_cascade = cv2.CascadeClassifier(cascade_path)
                print(f"âœ… {name}æ£€æµ‹å™¨: {filename}")
            else:
                print(f"âš ï¸ {name}æ£€æµ‹å™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼°ç®—ä½ç½®: {filename}")

    def detect_face(self, image_path):
        """ä¸»æ£€æµ‹æ–¹æ³• - è¿”å›äººè„¸å›¾åƒã€ç½®ä¿¡åº¦å’Œæ¤­åœ†ä¿¡æ¯"""
        try:
            print(f"ğŸ” å¼€å§‹äººè„¸æ£€æµ‹: {image_path}")

            # è¯»å–å›¾åƒ
            image = cv2.imread(str(image_path))
            if image is None:
                print("âŒ æ— æ³•è¯»å–å›¾åƒ")
                return None, 0, None

            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

            # å›¾åƒå¢å¼º
            gray = cv2.equalizeHist(gray)

            # é¦–å…ˆæ£€æµ‹äººè„¸åŒºåŸŸ
            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(60, 60)  # é€‚å½“çš„æœ€å°å°ºå¯¸
            )

            if len(faces) == 0:
                print("âŒ æœªæ£€æµ‹åˆ°äººè„¸ï¼Œå°è¯•æ”¾å®½å‚æ•°...")
                # å°è¯•æ”¾å®½å‚æ•°
                faces = self.face_cascade.detectMultiScale(
                    gray,
                    scaleFactor=1.05,
                    minNeighbors=3,
                    minSize=(40, 40)
                )

            if len(faces) == 0:
                print("âŒ æœ€ç»ˆæœªæ£€æµ‹åˆ°äººè„¸")
                return None, 0, None

            # é€‰æ‹©æœ€å¤§çš„äººè„¸
            faces = sorted(faces, key=lambda rect: rect[2] * rect[3], reverse=True)
            x, y, w, h = faces[0]
            print(f"âœ… æ£€æµ‹åˆ°äººè„¸: ä½ç½®({x},{y}), å°ºå¯¸({w}x{h})")

            # åœ¨äººè„¸åŒºåŸŸå†…æ£€æµ‹äº”å®˜
            face_roi_gray = gray[y:y + h, x:x + w]

            # æ£€æµ‹å„ä¸ªé¢éƒ¨ç‰¹å¾
            features = self._detect_all_features(face_roi_gray, x, y, w, h)

            # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(features, w * h, image.shape[0] * image.shape[1])

            # è·å–æ¤­åœ†è£å‰ªçš„äººè„¸åŒºåŸŸ
            face_region, ellipse_info = self._get_ellipse_face_region_with_info(image, (x, y, w, h), features)

            if face_region is None:
                print("âŒ æ¤­åœ†è£å‰ªå¤±è´¥ï¼Œä½¿ç”¨çŸ©å½¢è£å‰ª")
                face_region = image[y:y + h, x:x + w]
                # åˆ›å»ºé»˜è®¤æ¤­åœ†ä¿¡æ¯
                center_x = x + w // 2
                center_y = y + h // 2
                ellipse_width = int(w * 0.9)
                ellipse_height = int(h * 0.8)
                ellipse_info = {
                    'center': (center_x, center_y),
                    'size': (ellipse_width, ellipse_height),
                    'image_size': image.shape[:2],
                    'face_rect': (x, y, w, h)
                }

            # è½¬æ¢ä¸ºPILå›¾åƒ
            face_pil = Image.fromarray(cv2.cvtColor(face_region, cv2.COLOR_BGR2RGB))

            # è°ƒæ•´å¤§å°
            face_resized = self._resize_face_image(face_pil, ellipse_info)

            print(f"ğŸ¯ äººè„¸æ£€æµ‹å®Œæˆ: å°ºå¯¸{face_resized.size}, ç½®ä¿¡åº¦{confidence:.3f}")
            return face_resized, confidence, ellipse_info

        except Exception as e:
            print(f"âŒ äººè„¸æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return None, 0, None

    def _detect_all_features(self, face_gray, face_x, face_y, face_w, face_h):
        """æ£€æµ‹æ‰€æœ‰å¯ç”¨çš„é¢éƒ¨ç‰¹å¾"""
        features = {
            'eyes': [],
            'nose': [],
            'mouth': []
        }

        # æ£€æµ‹çœ¼ç›ï¼ˆé€šå¸¸æœ€å¯é ï¼‰
        try:
            eyes = self.eye_cascade.detectMultiScale(
                face_gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(20, 20)
            )
            for (ex, ey, ew, eh) in eyes:
                # è°ƒæ•´åˆ°åŸå›¾åæ ‡
                abs_x = face_x + ex
                abs_y = face_y + ey
                features['eyes'].append((abs_x, abs_y, ew, eh))
            print(f"ğŸ‘€ æ£€æµ‹åˆ° {len(features['eyes'])} ä¸ªçœ¼ç›")
        except Exception as e:
            print(f"âš ï¸ çœ¼ç›æ£€æµ‹å¤±è´¥: {e}")

        # å¦‚æœé¼»å­æ£€æµ‹å™¨å¯ç”¨åˆ™æ£€æµ‹é¼»å­
        if self.nose_cascade is not None:
            try:
                noses = self.nose_cascade.detectMultiScale(
                    face_gray,
                    scaleFactor=1.1,
                    minNeighbors=5
                )
                for (nx, ny, nw, nh) in noses:
                    abs_x = face_x + nx
                    abs_y = face_y + ny
                    features['nose'].append((abs_x, abs_y, nw, nh))
                print(f"ğŸ‘ƒ æ£€æµ‹åˆ° {len(features['nose'])} ä¸ªé¼»å­")
            except Exception as e:
                print(f"âš ï¸ é¼»å­æ£€æµ‹å¤±è´¥: {e}")

        # å¦‚æœå˜´å·´æ£€æµ‹å™¨å¯ç”¨åˆ™æ£€æµ‹å˜´å·´
        if self.mouth_cascade is not None:
            try:
                # åœ¨è„¸éƒ¨ä¸‹åŠéƒ¨åˆ†æ£€æµ‹å˜´å·´
                mouth_region = face_gray[int(face_gray.shape[0] * 0.6):, :]
                mouths = self.mouth_cascade.detectMultiScale(
                    mouth_region,
                    scaleFactor=1.1,
                    minNeighbors=15,
                    minSize=(30, 15)
                )
                for (mx, my, mw, mh) in mouths:
                    abs_x = face_x + mx
                    abs_y = face_y + int(face_gray.shape[0] * 0.6) + my
                    features['mouth'].append((abs_x, abs_y, mw, mh))
                print(f"ğŸ‘„ æ£€æµ‹åˆ° {len(features['mouth'])} ä¸ªå˜´å·´")
            except Exception as e:
                print(f"âš ï¸ å˜´å·´æ£€æµ‹å¤±è´¥: {e}")

        return features

    def _get_ellipse_face_region_with_info(self, image, face_rect, features):
        """è·å–æ¤­åœ†é¢éƒ¨åŒºåŸŸå¹¶è¿”å›æ¤­åœ†ä¿¡æ¯"""
        try:
            x, y, w, h = face_rect

            # è®¡ç®—æ¤­åœ†å‚æ•°
            center_x = x + w // 2
            center_y = y + h // 2
            ellipse_width = int(w * 0.9)
            ellipse_height = int(h * 0.8)

            # åˆ›å»ºæ¤­åœ†ä¿¡æ¯
            ellipse_info = {
                'center': (center_x, center_y),
                'size': (ellipse_width, ellipse_height),
                'image_size': image.shape[:2],
                'face_rect': (x, y, w, h)
            }

            # è®¡ç®—è£å‰ªåŒºåŸŸ
            roi_x = max(0, center_x - ellipse_width // 2)
            roi_y = max(0, center_y - ellipse_height // 2)
            roi_x2 = min(image.shape[1], center_x + ellipse_width // 2)
            roi_y2 = min(image.shape[0], center_y + ellipse_height // 2)

            # è£å‰ªåŒºåŸŸ
            cropped_region = image[roi_y:roi_y2, roi_x:roi_x2]

            # åˆ›å»ºæ¤­åœ†é®ç½©
            height, width = cropped_region.shape[:2]
            rgba_image = np.zeros((height, width, 4), dtype=np.uint8)

            # å¤åˆ¶RGBé€šé“
            rgba_image[:, :, :3] = cropped_region

            # åˆ›å»ºæ¤­åœ†é®ç½©
            mask = np.zeros((height, width), dtype=np.uint8)
            center_local_x = width // 2
            center_local_y = height // 2

            cv2.ellipse(mask,
                        (center_local_x, center_local_y),
                        (ellipse_width // 2, ellipse_height // 2),
                        0, 0, 360, 255, -1)

            # åº”ç”¨é®ç½©
            rgba_image[:, :, 3] = mask
            rgba_image[mask == 0] = [0, 0, 0, 0]

            print(f"âœ… æ¤­åœ†è£å‰ªå®Œæˆ - å°ºå¯¸: {ellipse_width}x{ellipse_height}")
            return rgba_image, ellipse_info

        except Exception as e:
            print(f"âš ï¸ æ¤­åœ†è£å‰ªå¤±è´¥: {e}")
            return None, None

    def _resize_face_image(self, face_image, ellipse_info):
        """è°ƒæ•´äººè„¸å›¾åƒå¤§å°"""
        max_size = Config.MAX_FACE_SIZE
        original_width, original_height = face_image.size

        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
        if original_width > original_height:
            new_width = max_size
            new_height = int(original_height * max_size / original_width)
            scale_factor = max_size / original_width
        else:
            new_height = max_size
            new_width = int(original_width * max_size / original_height)
            scale_factor = max_size / original_height

        # ç¡®ä¿æœ€å°å°ºå¯¸
        new_width = max(new_width, 100)
        new_height = max(new_height, 100)

        # è®°å½•ç¼©æ”¾å› å­
        ellipse_info['scale_factor'] = scale_factor
        ellipse_info['resized_size'] = (new_width, new_height)

        # é«˜è´¨é‡é‡é‡‡æ ·
        return face_image.resize((new_width, new_height), Image.LANCZOS)

    def _calculate_confidence(self, features, face_area, image_area):
        """è®¡ç®—æ£€æµ‹ç½®ä¿¡åº¦"""
        # åŸºç¡€ç½®ä¿¡åº¦åŸºäºäººè„¸å¤§å°
        area_ratio = face_area / image_area
        base_confidence = min(area_ratio * 8, 0.6)

        # æ ¹æ®æ£€æµ‹åˆ°çš„ç‰¹å¾æ•°é‡å¢åŠ ç½®ä¿¡åº¦
        feature_count = sum(len(features[key]) for key in features)

        if feature_count >= 3:
            feature_bonus = 0.3
        elif feature_count >= 2:
            feature_bonus = 0.2
        elif feature_count >= 1:
            feature_bonus = 0.1
        else:
            feature_bonus = 0.0

        confidence = min(base_confidence + feature_bonus, 1.0)

        print(f"ğŸ“Š ç½®ä¿¡åº¦è®¡ç®—: é¢ç§¯æ¯”ä¾‹{area_ratio:.4f}, ç‰¹å¾æ•°{feature_count}, æœ€ç»ˆ{confidence:.3f}")
        return confidence

    def apply_border_cleanup(self, image, ellipse_info, border_pixels):
        """åº”ç”¨è¾¹ç•Œæ¸…ç† - å…¼å®¹æ—§ç‰ˆæœ¬"""
        try:
            if border_pixels <= 0:
                return image

            print(f"ğŸ§¹ åº”ç”¨è¾¹ç•Œæ¸…ç†: {border_pixels}åƒç´ ")

            # å¦‚æœå›¾åƒä¸æ˜¯RGBAï¼Œå…ˆè½¬æ¢ä¸ºRGBA
            if image.mode != 'RGBA':
                image = image.convert('RGBA')

            img_array = np.array(image)
            height, width = img_array.shape[:2]

            # è®¡ç®—ç¼©æ”¾åçš„æ¤­åœ†å‚æ•°
            scale_factor = ellipse_info.get('scale_factor', 1.0)
            original_size = ellipse_info['size']

            scaled_width = int(original_size[0] * scale_factor) - border_pixels * 2
            scaled_height = int(original_size[1] * scale_factor) - border_pixels * 2
            scaled_width = max(20, scaled_width)
            scaled_height = max(20, scaled_height)

            print(f"ğŸ“ ç¼©æ”¾åæ¤­åœ†å°ºå¯¸: {scaled_width}x{scaled_height}")

            # åˆ›å»ºæ¤­åœ†é®ç½©
            center_x, center_y = width // 2, height // 2
            mask = np.zeros((height, width), dtype=np.uint8)

            # ç»˜åˆ¶æ¤­åœ†ï¼ˆå†…ç¼©è¾¹ç•Œæ¸…ç†åƒç´ ï¼‰
            cv2.ellipse(mask,
                        (center_x, center_y),
                        (scaled_width // 2, scaled_height // 2),
                        0, 0, 360, 255, -1)

            # åº”ç”¨é®ç½©ï¼šæ¤­åœ†å¤–å®Œå…¨é€æ˜ï¼Œä¸”RGBå€¼è®¾ä¸º0
            img_array[:, :, 3] = mask
            img_array[mask == 0] = [0, 0, 0, 0]

            print("âœ… è¾¹ç•Œæ¸…ç†å®Œæˆ")
            return Image.fromarray(img_array)

        except Exception as e:
            print(f"âŒ è¾¹ç•Œæ¸…ç†å¤±è´¥: {e}")
            return image

    # å‘åå…¼å®¹çš„æ–¹æ³• - ä¸åŸè“å›¾ä¿æŒç›¸åŒ
    def detect_facial_features_with_confidence(self, image_path, border_cleanup_pixels=0):
        """å‘åå…¼å®¹çš„æ—§æ–¹æ³•å"""
        print("âš ï¸ ä½¿ç”¨æ—§æ–¹æ³•å detect_facial_features_with_confidence")
        return self.detect_face(image_path)

    def detect_and_crop_face(self, image_path, border_cleanup_pixels=0):
        """å¦ä¸€ä¸ªå‘åå…¼å®¹çš„æ–¹æ³•"""
        print("âš ï¸ ä½¿ç”¨æ—§æ–¹æ³•å detect_and_crop_face")
        return self.detect_face(image_path)
