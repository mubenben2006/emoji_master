import cv2
import numpy as np
from PIL import Image, ImageDraw
import os
from config import Config


class FaceDetector:
    """äº”å®˜æ£€æµ‹æ¨¡å— - ä½¿ç”¨OpenCV Haarçº§è”åˆ†ç±»å™¨æ£€æµ‹é¢éƒ¨ç‰¹å¾"""

    def __init__(self):
        # åŠ è½½åŸºç¡€äººè„¸æ£€æµ‹å™¨
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )

        # åŠ è½½å¯ç”¨çš„äº”å®˜æ£€æµ‹å™¨
        self.eye_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_eye.xml'
        )

        # é¼»å­å’Œå˜´å·´æ£€æµ‹å™¨åˆå§‹åŒ–ä¸ºNone
        self.nose_cascade = None
        self.mouth_cascade = None

        # æ£€æŸ¥å¹¶åˆå§‹åŒ–æ‰€æœ‰çº§è”å™¨ï¼ˆè·³è¿‡ä¸‹è½½ï¼‰
        self._initialize_cascades_skip_download()

    def _initialize_cascades_skip_download(self):
        """åˆå§‹åŒ–çº§è”åˆ†ç±»å™¨ - è·³è¿‡ä¸‹è½½ï¼Œç›´æ¥ä½¿ç”¨å¯ç”¨çš„"""
        print("ğŸ”§ åˆå§‹åŒ–é¢éƒ¨ç‰¹å¾æ£€æµ‹å™¨...")

        # åŸºç¡€çº§è”å™¨ï¼ˆé€šå¸¸éƒ½å¯ç”¨ï¼‰
        base_cascades = {
            'face': 'haarcascade_frontalface_default.xml',
            'eyes': 'haarcascade_eye.xml'
        }

        # å¯é€‰çš„çº§è”å™¨
        optional_cascades = {
            'nose': 'haarcascade_mcs_nose.xml',
            'mouth': 'haarcascade_smile.xml'
        }

        # æ£€æŸ¥åŸºç¡€çº§è”å™¨
        for name, filename in base_cascades.items():
            cascade_path = cv2.data.haarcascades + filename
            if os.path.exists(cascade_path):
                print(f"âœ… {name}æ£€æµ‹å™¨: {filename}")
            else:
                print(f"âŒ {name}æ£€æµ‹å™¨ç¼ºå¤±: {filename}")

        # æ£€æŸ¥å¯é€‰çº§è”å™¨ï¼Œå¦‚æœä¸å­˜åœ¨å°±è·³è¿‡
        for name, filename in optional_cascades.items():
            cascade_path = cv2.data.haarcascades + filename
            if os.path.exists(cascade_path):
                if name == 'nose':
                    self.nose_cascade = cv2.CascadeClassifier(cascade_path)
                elif name == 'mouth':
                    self.mouth_cascade = cv2.CascadeClassifier(cascade_path)
                print(f"âœ… {name}æ£€æµ‹å™¨: {filename}")
            else:
                print(f"âš ï¸ {name}æ£€æµ‹å™¨ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼°ç®—ä½ç½®: {filename}")

    def detect_facial_features_with_confidence(self, image_path, border_cleanup_pixels=3):
        """æ£€æµ‹é¢éƒ¨äº”å®˜ - è¿”å›äººè„¸å›¾åƒå’Œæ¤­åœ†ä¿¡æ¯ï¼ˆä¸è¿›è¡Œè¾¹ç•Œæ¸…ç†ï¼‰"""
        try:
            image = cv2.imread(image_path)
            if image is None:
                print("âŒ æ— æ³•è¯»å–å›¾åƒ")
                return None, 0, None

            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

            # é¦–å…ˆæ£€æµ‹äººè„¸åŒºåŸŸ
            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(50, 50)
            )

            if len(faces) == 0:
                print("âŒ æœªæ£€æµ‹åˆ°äººè„¸")
                return None, 0, None

            # é€‰æ‹©æœ€å¤§çš„äººè„¸
            x, y, w, h = max(faces, key=lambda rect: rect[2] * rect[3])
            print(f"âœ… æ£€æµ‹åˆ°äººè„¸: ä½ç½®({x},{y}), å°ºå¯¸({w}x{h})")

            # åœ¨äººè„¸åŒºåŸŸå†…æ£€æµ‹äº”å®˜
            face_roi_gray = gray[y:y + h, x:x + w]

            # æ£€æµ‹å„ä¸ªé¢éƒ¨ç‰¹å¾
            features = self._detect_all_features(face_roi_gray, x, y, w, h)

            # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
            confidence = self._calculate_confidence(features, w * h, image.shape[0] * image.shape[1])

            # è·å–æ¤­åœ†è£å‰ªçš„é¢éƒ¨ç‰¹å¾åŒºåŸŸï¼ˆä¸è¿›è¡Œè¾¹ç•Œæ¸…ç†ï¼‰
            feature_region, ellipse_info = self._get_ellipse_face_region_with_info(
                image, (x, y, w, h), features, 0  # è¿™é‡Œä¼ å…¥0ï¼Œè¡¨ç¤ºä¸æ¸…ç†è¾¹ç•Œ
            )

            if feature_region is None:
                print("âŒ æ¤­åœ†è£å‰ªå¤±è´¥ï¼Œä½¿ç”¨çŸ©å½¢è£å‰ª")
                feature_region = image[y:y + h, x:x + w]
                # åˆ›å»ºé»˜è®¤æ¤­åœ†ä¿¡æ¯
                center_x = x + w // 2
                center_y = y + h // 2
                ellipse_width = int(w * 0.9)
                ellipse_height = int(h * 0.8)
                ellipse_info = {
                    'center': (center_x, center_y),
                    'original_size': (ellipse_width, ellipse_height),
                    'border_cleanup': border_cleanup_pixels,  # è®°å½•æ¸…ç†å‚æ•°ï¼Œä½†å®é™…ä¸åº”ç”¨
                    'image_size': image.shape[:2],  # (height, width)
                    'scale_factor': 1.0  # åˆå§‹ç¼©æ”¾å› å­
                }

            # è½¬æ¢ä¸ºPILå›¾åƒ
            feature_pil = Image.fromarray(cv2.cvtColor(feature_region, cv2.COLOR_BGR2RGB))

            # è®¡ç®—ç¼©æ”¾å› å­å¹¶è®°å½•
            max_size = getattr(Config, 'MAX_FACE_SIZE', 256)
            original_width, original_height = feature_pil.size

            # ä¿æŒå®½é«˜æ¯”è°ƒæ•´å¤§å°
            if original_width > original_height:
                new_width = max_size
                new_height = int(original_height * max_size / original_width)
                scale_factor = max_size / original_width
            else:
                new_height = max_size
                new_width = int(original_width * max_size / original_height)
                scale_factor = max_size / original_height

            feature_resized = feature_pil.resize((new_width, new_height), Image.LANCZOS)

            # æ›´æ–°æ¤­åœ†ä¿¡æ¯ä¸­çš„ç¼©æ”¾å› å­
            ellipse_info['scale_factor'] = scale_factor
            ellipse_info['resized_size'] = (new_width, new_height)

            print(f"âœ… æ¤­åœ†é¢éƒ¨ç‰¹å¾æ£€æµ‹å®Œæˆ - ç½®ä¿¡åº¦: {confidence:.3f}")
            print(f"âœ… æ¤­åœ†ä¿¡æ¯è®°å½•: ä¸­å¿ƒ{ellipse_info['center']}, åŸå§‹å°ºå¯¸{ellipse_info['original_size']}")
            print(f"âœ… ç¼©æ”¾å› å­: {scale_factor:.4f}, æœ€ç»ˆç‰¹å¾å°ºå¯¸: {feature_resized.size}")

            return feature_resized, confidence, ellipse_info

        except Exception as e:
            print(f"âŒ é¢éƒ¨ç‰¹å¾æ£€æµ‹é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return None, 0, None

    def _get_ellipse_face_region_with_info(self, image, face_rect, features, border_pixels=0):
        """è·å–æ¤­åœ†é¢éƒ¨åŒºåŸŸå¹¶è¿”å›æ¤­åœ†ä¿¡æ¯ï¼ˆå¯é€‰æ‹©æ˜¯å¦æ¸…ç†è¾¹ç•Œï¼‰"""
        try:
            x, y, w, h = face_rect

            # è®¡ç®—æ¤­åœ†å‚æ•°
            center_x = x + w // 2
            center_y = y + h // 2
            ellipse_width = int(w * 0.9)
            ellipse_height = int(h * 0.8)

            # å¦‚æœæŒ‡å®šäº†è¾¹ç•Œæ¸…ç†ï¼Œåˆ™å†…ç¼©æ¤­åœ†
            if border_pixels > 0:
                ellipse_width = max(10, ellipse_width - border_pixels * 2)
                ellipse_height = max(10, ellipse_height - border_pixels * 2)
                print(f"ğŸ”§ åº”ç”¨è¾¹ç•Œæ¸…ç†: æ¤­åœ†å°ºå¯¸å†…ç¼© {border_pixels} åƒç´ ")

            # åˆ›å»ºæ¤­åœ†ä¿¡æ¯
            ellipse_info = {
                'center': (center_x, center_y),
                'original_size': (ellipse_width, ellipse_height),
                'border_cleanup': border_pixels,
                'image_size': image.shape[:2]  # (height, width)
            }

            # åˆ›å»ºç™½è‰²èƒŒæ™¯
            white_background = np.ones_like(image) * 255

            # åˆ›å»ºæ¤­åœ†æ©ç 
            mask = np.zeros(image.shape[:2], dtype=np.uint8)

            # ç»˜åˆ¶æ¤­åœ†
            cv2.ellipse(mask,
                        (center_x, center_y),
                        (ellipse_width // 2, ellipse_height // 2),
                        0, 0, 360, 255, -1)

            # åº”ç”¨æ©ç ï¼šæ¤­åœ†å†…ä¿ç•™åŸå›¾ï¼Œæ¤­åœ†å¤–æ˜¾ç¤ºç™½è‰²
            elliptical_face = np.where(
                mask[:, :, np.newaxis] == 255,
                image,
                white_background
            ).astype(np.uint8)

            # è£å‰ªæ¤­åœ†åŒºåŸŸ
            roi_x = max(0, center_x - ellipse_width // 2)
            roi_y = max(0, center_y - ellipse_height // 2)
            roi_x2 = min(image.shape[1], center_x + ellipse_width // 2)
            roi_y2 = min(image.shape[0], center_y + ellipse_height // 2)

            cropped_face = elliptical_face[roi_y:roi_y2, roi_x:roi_x2]

            print(f"âœ… æ¤­åœ†è£å‰ªå®Œæˆ - å°ºå¯¸: {ellipse_width}x{ellipse_height}, æ¸…ç†: {border_pixels}åƒç´ ")

            return cropped_face, ellipse_info

        except Exception as e:
            print(f"âš ï¸ æ¤­åœ†è£å‰ªå¤±è´¥: {e}")
            return None, None

    def _detect_all_features(self, face_gray, face_x, face_y, face_w, face_h):
        """æ£€æµ‹æ‰€æœ‰å¯ç”¨çš„é¢éƒ¨ç‰¹å¾"""
        features = {
            'eyes': [],
            'nose': [],
            'mouth': []
        }

        # æ£€æµ‹çœ¼ç›ï¼ˆé€šå¸¸æœ€å¯é ï¼‰
        try:
            eyes = self.eye_cascade.detectMultiScale(
                face_gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(20, 20)
            )
            for (ex, ey, ew, eh) in eyes:
                # è°ƒæ•´åˆ°åŸå›¾åæ ‡
                abs_x = face_x + ex
                abs_y = face_y + ey
                features['eyes'].append((abs_x, abs_y, ew, eh))
            print(f"ğŸ‘€ æ£€æµ‹åˆ° {len(features['eyes'])} ä¸ªçœ¼ç›")
        except Exception as e:
            print(f"âš ï¸ çœ¼ç›æ£€æµ‹å¤±è´¥: {e}")

        # å¦‚æœé¼»å­æ£€æµ‹å™¨ä¸å¯ç”¨ï¼Œä¼°ç®—é¼»å­ä½ç½®
        if self.nose_cascade is not None:
            try:
                noses = self.nose_cascade.detectMultiScale(
                    face_gray,
                    scaleFactor=1.1,
                    minNeighbors=5
                )
                for (nx, ny, nw, nh) in noses:
                    abs_x = face_x + nx
                    abs_y = face_y + ny
                    features['nose'].append((abs_x, abs_y, nw, nh))
                print(f"ğŸ‘ƒ æ£€æµ‹åˆ° {len(features['nose'])} ä¸ªé¼»å­")
            except Exception as e:
                print(f"âš ï¸ é¼»å­æ£€æµ‹å¤±è´¥: {e}")
        else:
            # ä¼°ç®—é¼»å­ä½ç½®ï¼ˆåœ¨äººè„¸ä¸­å¿ƒåä¸‹ï¼‰
            nose_x = face_x + face_w // 2
            nose_y = face_y + face_h // 2
            nose_w = face_w // 6
            nose_h = face_h // 8
            features['nose'].append((nose_x - nose_w // 2, nose_y - nose_h // 2, nose_w, nose_h))
            print("ğŸ‘ƒ ä½¿ç”¨ä¼°ç®—é¼»å­ä½ç½®")

        # å¦‚æœå˜´å·´æ£€æµ‹å™¨ä¸å¯ç”¨ï¼Œä¼°ç®—å˜´å·´ä½ç½®
        if self.mouth_cascade is not None:
            try:
                # åœ¨è„¸éƒ¨ä¸‹åŠéƒ¨åˆ†æ£€æµ‹å˜´å·´
                mouth_region = face_gray[int(face_gray.shape[0] * 0.6):, :]
                mouths = self.mouth_cascade.detectMultiScale(
                    mouth_region,
                    scaleFactor=1.1,
                    minNeighbors=15,
                    minSize=(30, 15)
                )
                for (mx, my, mw, mh) in mouths:
                    abs_x = face_x + mx
                    abs_y = face_y + int(face_gray.shape[0] * 0.6) + my
                    features['mouth'].append((abs_x, abs_y, mw, mh))
                print(f"ğŸ‘„ æ£€æµ‹åˆ° {len(features['mouth'])} ä¸ªå˜´å·´")
            except Exception as e:
                print(f"âš ï¸ å˜´å·´æ£€æµ‹å¤±è´¥: {e}")
        else:
            # ä¼°ç®—å˜´å·´ä½ç½®ï¼ˆåœ¨äººè„¸ä¸‹éƒ¨ï¼‰
            mouth_x = face_x + face_w // 4
            mouth_y = face_y + int(face_h * 0.7)
            mouth_w = face_w // 2
            mouth_h = face_h // 6
            features['mouth'].append((mouth_x, mouth_y, mouth_w, mouth_h))
            print("ğŸ‘„ ä½¿ç”¨ä¼°ç®—å˜´å·´ä½ç½®")

        return features

    def _calculate_confidence(self, features, face_area, image_area):
        """è®¡ç®—æ£€æµ‹ç½®ä¿¡åº¦"""
        confidence = 0.0

        # åŸºç¡€ç½®ä¿¡åº¦åŸºäºäººè„¸å¤§å°
        base_confidence = min(face_area / image_area * 10, 0.5)

        # æ ¹æ®æ£€æµ‹åˆ°çš„ç‰¹å¾æ•°é‡å¢åŠ ç½®ä¿¡åº¦
        feature_count = sum(len(features[key]) for key in features)

        if feature_count >= 3:
            confidence = base_confidence + 0.4
        elif feature_count >= 2:
            confidence = base_confidence + 0.3
        elif feature_count >= 1:
            confidence = base_confidence + 0.2
        else:
            confidence = base_confidence

        return min(confidence, 1.0)

    def apply_final_border_cleanup(self, processed_image, ellipse_info, border_cleanup_pixels):
        """åœ¨æœ€ç»ˆå¤„ç†åçš„å›¾åƒä¸Šåº”ç”¨è¾¹ç•Œæ¸…ç†"""
        try:
            print(f"ğŸ¯ åº”ç”¨æœ€ç»ˆè¾¹ç•Œæ¸…ç†: {border_cleanup_pixels} åƒç´ ")

            # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
            if isinstance(processed_image, Image.Image):
                img_array = np.array(processed_image)
            else:
                img_array = processed_image.copy()

            # è·å–å›¾åƒå°ºå¯¸
            height, width = img_array.shape[:2]

            # è®¡ç®—ç¼©æ”¾åçš„æ¤­åœ†å‚æ•°
            scale_factor = ellipse_info.get('scale_factor', 1.0)
            original_center = ellipse_info['center']
            original_size = ellipse_info['original_size']

            # è®¡ç®—åœ¨ç¼©æ”¾åå›¾åƒä¸­çš„æ¤­åœ†ä¸­å¿ƒï¼ˆç›¸å¯¹ä½ç½®ï¼‰
            # ç”±äºå›¾åƒå·²ç»è¿‡è£å‰ªå’Œç¼©æ”¾ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°è®¡ç®—ä¸­å¿ƒç‚¹
            scaled_center_x = width // 2
            scaled_center_y = height // 2

            # è®¡ç®—ç¼©æ”¾åçš„æ¤­åœ†å°ºå¯¸ï¼ˆè€ƒè™‘è¾¹ç•Œæ¸…ç†ï¼‰
            scaled_ellipse_width = int(original_size[0] * scale_factor) - border_cleanup_pixels * 2
            scaled_ellipse_height = int(original_size[1] * scale_factor) - border_cleanup_pixels * 2

            # ç¡®ä¿æ¤­åœ†å°ºå¯¸ä¸ä¼šå¤ªå°
            scaled_ellipse_width = max(10, scaled_ellipse_width)
            scaled_ellipse_height = max(10, scaled_ellipse_height)

            print(
                f"ğŸ“ ç¼©æ”¾åæ¤­åœ†å‚æ•°: ä¸­å¿ƒ({scaled_center_x},{scaled_center_y}), å°ºå¯¸({scaled_ellipse_width}x{scaled_ellipse_height})")

            # åˆ›å»ºç™½è‰²èƒŒæ™¯
            if len(img_array.shape) == 3:  # å½©è‰²å›¾åƒ
                white_background = np.ones_like(img_array) * 255
            else:  # ç°åº¦å›¾åƒ
                white_background = np.ones_like(img_array) * 255

            # åˆ›å»ºæ¤­åœ†æ©ç 
            mask = np.zeros((height, width), dtype=np.uint8)

            # ç»˜åˆ¶æ¤­åœ†ï¼ˆä¸­å¿ƒä¸å˜ï¼Œå°ºå¯¸å†…ç¼©ï¼‰
            cv2.ellipse(mask,
                        (scaled_center_x, scaled_center_y),
                        (scaled_ellipse_width // 2, scaled_ellipse_height // 2),
                        0, 0, 360, 255, -1)

            # åº”ç”¨æ©ç ï¼šæ¤­åœ†å†…ä¿ç•™åŸå›¾ï¼Œæ¤­åœ†å¤–æ˜¾ç¤ºç™½è‰²
            if len(img_array.shape) == 3:  # å½©è‰²å›¾åƒ
                result = np.where(
                    mask[:, :, np.newaxis] == 255,
                    img_array,
                    white_background
                ).astype(np.uint8)
            else:  # ç°åº¦å›¾åƒ
                result = np.where(
                    mask == 255,
                    img_array,
                    white_background
                ).astype(np.uint8)

            # è½¬æ¢å›PILå›¾åƒ
            final_image = Image.fromarray(result)

            print(f"âœ… æœ€ç»ˆè¾¹ç•Œæ¸…ç†å®Œæˆ - å†…ç¼© {border_cleanup_pixels} åƒç´ ")
            return final_image

        except Exception as e:
            print(f"âŒ æœ€ç»ˆè¾¹ç•Œæ¸…ç†å¤±è´¥: {e}")
            return processed_image

    # å‘åå…¼å®¹çš„æ–¹æ³•
    def detect_faces_with_confidence(self, image_path, border_cleanup_pixels=3):
        """å‘åå…¼å®¹çš„æ—§æ–¹æ³•å"""
        print("âš ï¸ ä½¿ç”¨æ—§æ–¹æ³•å detect_faces_with_confidence")
        return self.detect_facial_features_with_confidence(image_path, border_cleanup_pixels)

    def detect_and_crop_face(self, image_path, border_cleanup_pixels=3):
        """å¦ä¸€ä¸ªå‘åå…¼å®¹çš„æ–¹æ³•"""
        print("âš ï¸ ä½¿ç”¨æ—§æ–¹æ³•å detect_and_crop_face")
        return self.detect_facial_features_with_confidence(image_path, border_cleanup_pixels)
